# 로드 밸런싱

## 로드 밸런싱이란?

🔍 부하 분산이라고도 하며, 해석 그대로 서버에 가해지는 부하(=로드)를 분산(=밸런싱)해주는 기술

즉, 트래픽을 여러 서버에 분산시키는 행위나 기술

## 로드 밸런서란?

🔍 클라이언트와 서버 그룹 사이에 위치해, 서버의 부하를 분산시키는 하드웨어 또는 소프트웨어

즉, 트래픽을 여러 서버에 분산시키는 행위를 수행하는 장치

## 로드 밸런서가 필요한 이유

서비스의 규모가 커지고 접속하는 클라이언트 수가 많아지면, 하나의 서버로는 모든 요청을 처리하기 어려워짐.

-> 서버가 다운되거나, 응답 속도가 느려지거나 사용자에게 서비스 장애가 발생할 수 있음.

이처럼 트래픽이 늘어났을 때 2가지 해결 방법 :

1. Scale Up : 기존 한 대의 서버 성능을 높이는 방법 (ex. CPU, RAM 증가)

   → 하지만 이 방법은 기술적인 한계에 부딪힐 수 밖에 없음

2. Scale Out : 비슷한 성능의 서버를 여러 대 증설하는 방법

   → 서버가 여러 대로 나눠지기 때문에 특정 서버에 트래픽이 몰리지 않도록 각 서버에 트래픽을 균등하게 나눠주는 로드 밸런싱 기술이 필요함.

   ⭐ 이처럼 서버의 과부하를 방지하기 위한 방법 중 ‘스케일 아웃’ 방식에서 로드 밸런서가 필요!

## 로드 밸런서의 종류

L4, L7 로드 밸런서가 가장 많이 사용됨.

➡️ L4 로드 밸런서부터 포트를 다룰 수 있기 때문에 포트 번호를 바탕으로 부하를 분산하는 것이 가능하기 때문

### L4 로드 밸런서 (Transport Layer, 전송 계층)

- 전송 계층에서 로드를 분산
- 분산 기준: IP 주소, 포트 번호, 프로토콜 등 패킷 정보 기반

  → 패킷 안을 보지 않고 연결 정보(헤더 정보)만을 기준으로 로드를 분산

- 속도가 빠르고 효율이 높음
- 섬세한 라우팅이 불가능
- L7 로드 밸런서보다 저렴

### L7 로드 밸런서 (Application Layer, 응용 계층)

- 응용 계층에서 로드를 분산
- 분산 기준: HTTP 메서드, URL, 쿠키, 세션 등과 같은 사용자 요청 기반
  → 패킷 안의 내용을 확인하고 그 내용에 따라 로드를 특정 서버에 분산
- 섬세한 라우팅이 가능하고, 비정상적인 트래픽을 필터링 할 수 있음.
- 패킷의 내용을 복호화 해야하기 때문에 더 많은 비용이 듦.

## 로드 밸런싱 알고리즘 종류

### **Round robin**

가장 단순하고 많이 사용되는 방식으로, 서버에 요청을 **순서대로** 분배

- 서버 A → B → C → A → B → …
- 서버의 성능, 현재 상태는 고려하지 않음

장점: 구현이 쉽고 균등하게 분산됨

단점: 각 서버의 성능이나 부하를 고려하지 않아 비효율적일 수 있음

### **Random select (무작위 분산)**

서버 중 **랜덤하게** 하나를 선택해서 요청을 분배

장점: 구현이 매우 간단

단점: 한 서버에 랜덤 하게 걸려서 해당 서버에 부하가 많이 걸리는 경우가 있을 수 있음

### **Least connections (최소 연결 방식)**

현재 **가장 적은 연결 수**를 가진 서버에 요청을 분배

- 서버에서 얼마나 많은 커넥션을 맺고 있는지를 알려주면 로드 밸런서는 이 정보를 이용해 어디로 요청을 보낼 지를 판단
- 실시간으로 서버의 연결 수를 체크

장점: 부하가 적은 서버에 우선 분산되어 효율적

단점: 서버의 연결 수 모니터링 필요, 유지 비용 증가

### **Weighted Round Robin (가중치 라운드 로빈)**

Round Robin 방식에 서버별 **가중치**를 부여하여 요청을 분배

- 성능이 좋은 서버에 더 많은 요청을 할당
- 예를 들어 A 서버(가중치 3)와 B 서버(가중치 1)가 있고 로드 밸런서가 클라이언트로부터 총 8개의 요청을 받았다면, A와 B 서버에 각 6개와 2개의 요청이 전달

장점: 서버 성능을 반영한 분산

단점: 설정 복잡도 증가

### **Least Response Time (최소 응답 시간)**

서버의 **평균 응답 시간**이 가장 빠른 서버에 요청을 분배

장점: 사용자의 체감 속도 향상

단점: 응답 시간 측정 필요

### **IP Hash**

클라이언트의 **IP 주소를 해싱**하여 특정 서버에 매핑

- 동일한 IP는 항상 같은 서버로 연결됨
- 세션 유지가 필요한 서비스에 유용 (ex. 로그인 상태 유지)

장점: 세션 유지 용이

단점: 서버가 추가/제거되면 해시 충돌 가능

## 헬스 체크

🔍 서버가 정상적으로 동작하는지 로드 밸런서가 주기적으로 확인하는 기능

- 동작 방식
  - 로드 밸런서가 주기적으로 각 서버에 요청을 보내서 응답 상태를 확인
  - 정상 응답 → 요청을 계속 분산
  - 비정상 응답 (ex. 응답 없음, 500 에러) → 해당 서버는 서비스 대상에서 제외
- 헬스 체크 방식
  - ICMP : 서버에 Ping을 보내 응답이 오는지 확인 (네트워크 레벨의 단순 생존 확인)
  - TCP 서비스 포트 : 서버의 특정 포트가 열려 있는지 확인 (예: 80, 443 등)
  - HTTP 상태 코드 : 서버의 HTTP 엔드포인트(e.g., `/health`)에 요청을 보내 상태 코드(200 OK 등)를 확인
    ➡️ HTTP 방식은 애플리케이션 레벨의 상태까지 확인 가능 → 가장 정밀함 & ICMP나 TCP는 네트워크나 서비스 레벨만 확인 가능

## 장애 조치

🔍 서버나 시스템에 장애가 발생했을 때, 로드 밸런서가 트래픽을 정상인 다른 서버로 자동 전환해주는 기능

- 동작 방식
  - 헬스 체크를 통해 서버 A에서 이상 감지
  - 서버 A를 서비스 대상에서 제외
  - A로 향하던 트래픽을 정상 상태인 다른 서버(B, C 등) 로 자동 분산
  - 서버 A가 회복되면(헬스 체크를 통해 확인) 다시 대상에 포함

## DNS 로드 밸런싱

🔍 별도의 하드웨어 장비나, 소프트웨어 없이 사용자가 DNS를 이용하여 도메인 정보를 조회하는 시점에서 트래픽을 분산하는 기법

→ DNS 서버가 하나의 도메인(예: `example.com`)에 대해 여러 IP 주소를 등록해놓고, 클라이언트가 요청할 때마다 다른 IP를 응답함으로써 트래픽을 여러 서버로 분산시킴.

- 동작 방식
  - 사용자가 `example.com`에 접속
  - 클라이언트는 DNS 서버에 IP 주소를 요청
  - DNS 서버는 등록된 여러 IP 중 하나를 반환
  - 클라이언트는 받은 IP로 접속해서 서버로 요청 전송
- 분산 방식
  - Round Robin : IP1 → IP2 → IP3 순으로 돌아가며 응답
  - Geo DNS (지리 기반) : 사용자 위치에 따라 가까운 서버 IP 반환
  - Latency-based (지연 기반) : 응답 속도가 빠른 서버 IP를 선택
- 장점
  - 중간 장비(로드밸런서 등) 없이도 서비스가 가능
  - 구현이 간단
  - 전 세계적으로 사용 가능 (CDN, 글로벌 트래픽 대응에 유리)
- 단점
  - 서버의 수 만큼 공인 IP 주소가 필요
  - 헬스 체크 기능이 없어서 서버에 장애가 발생해도 감지하지 않고 부하를 분산시킴
    → 무중단 서비스에 적합하지 않음
  - DNS 응답 결과를 클라이언트가 캐싱해서 재사용할 경우에 분산 효과가 줄어듦

## DNS 로드 밸런싱 VS 기존 로드 밸런싱

| 항목            | **DNS 로드 밸런싱**                       | **기존 로드 밸런싱 (L4/L7 등)**                      |
| --------------- | ----------------------------------------- | ---------------------------------------------------- |
| **동작 시점**   | 클라이언트가 DNS 질의할 때                | 클라이언트 요청이 서버로 전달될 때                   |
| **분산 기준**   | 도메인에 매핑된 여러 IP 중 하나 반환      | 요청의 세부 정보 (IP, 포트, URL, 쿠키, 세션 등) 기반 |
| **헬스 체크**   | 불가능 (기본 DNS는 서버 상태를 모름)      | 가능 (로드 밸런서가 실시간으로 서버 상태 확인)       |
| **트래픽 제어** | 불가능 (클라이언트가 받은 IP에 직접 접속) | 가능 (로드 밸런서가 트래픽 흐름을 제어)              |
| **정밀 제어**   | 불가능 (단순 IP 수준 분산)                | 가능 (트래픽 부하, 세션 유지 등 고려 가능)           |

# 웹 서버 & WAS

## 정적 페이지 vs 동적 페이지

### **정적 웹 페이지 (Static Web Page)**

🔍 웹 서버에 **이미 저장된 파일**(HTML 파일, 이미지, JavaScript 파일 등)을 클라이언트에게 전송하는 웹 페이지

- 사용자는 서버에 저장된 데이터가 변경되지 않는 한 고정된 웹 페이지를 계속 보게 됨
- 모든 사용자는 같은 결과의 웹 페이지를 서버에 요청하고 응답 받게 됨
- 장점
  - 다른 처리 없이 요청에 대한 파일만 전송하기 때문에 빠름
  - 단순한 문서로 웹 서버를 구축하므로 호스팅 서버에 연결하는 비용이 적음
- 단점
  - 저장된 정보만 보여주기 때문에 서비스가 한정적
  - 추가, 삭제, 수정 등의 작업이 모두 코드를 직접 건드려야 하기 때문에 관리가 힘듦

### 동적 웹 페이지 (Dynamic Web Page)

🔍 웹 서버에 저장된 HTML 파일이 그대로 브라우저에 나오는 것이 아닌, **동적으로 만들어지는 웹 페이지**

- 서버는 사용자의 요청을 해석하여 데이터를 가공한 후 웹 페이지를 동적으로 생성하여 사용자에게 보냄
- 사용자는 상황, 시간, 요청 등에 따라 달라지는 웹 페이지를 보게 됨
- 장점
  - 개인화된 콘텐츠 제공 가능
  - 효율적인 데이터 관리
  - 다양한 기능 구현 가능
- 단점
  - 매 요청마다 서버 로직을 실행하기 때문에 처리 속도 느림
  - 요청마다 처리 작업이 필요하므로 서버 리소스 소모 큼
  - 입력값 처리, 인증 처리 등으로 인해 보안 위험 요소 증가

## 웹 서버(WS) vs WAS

### WS란?

🔍 웹 브라우저(클라이언트)로 부터 HTTP 요청을 받아 **HTML** 문서와 같은 정적인 컨텐츠를 제공하는 서버

✅ 역할 : 정적 콘텐츠 제공

→ 클라이언트가 요청을 하면 웹서버는 이에 해당하는 정적 리소스를 찾아 응답

### WAS란?

🔍 다양한 로직 처리를 요구하는 동적인 컨텐츠를 처리하고 제공하는 서버

✅ 역할 : 동적 콘텐츠 처리 & 제공

→ 클라이언트가 요청을 하면 WAS는 비즈니스 로직을 실행하여 응답

- 주로 JAVA, PHP, Python, Ruby, Node.js 등 다양한 언어와 프레임워크를 사용하여 구축됨
- 대부분의 WAS는 WS를 내장하고 있기 때문에 HTTP 요청을 받을 수 있음

### WS와 WAS 활용 사례

실제 웹 서비스에서는 WS와 WAS가 함께 사용되는 경우가 많음

- ex. 온라인 쇼핑몰
  - WS : 상품 이미지나 스타일 정보 등 정적 콘텐츠를 제공
  - WAS : 사용자가 상품을 검색하거나 장바구니에 담는 등의 동적인 작업을 처리

## 웹 서버 ↔ WAS 협업 구조 (리버스 프록시)

- [클라이언트 - 웹 서버 - WAS - DB 서버] 구조
- 웹 서버가 앞단에서 **정적 리소스 처리 + 보안 + 로드밸런싱** 등을 담당하고 WAS는 오직 **동적 로직 처리**에만 집중하는 구조
- 웹 서버의 역할
  - 정적 파일 응답
  - ⭐ 클라이언트 요청을 WAS로 전달 (리버스 프록시 역할)
  - 여러 WAS로 요청을 분산 (로드 밸런싱)
  - HTTPS 처리, 인증, 보안 필터링
- WAS의 역할
  - 동적 요청 처리 (비즈니스 로직 수행)
  - DB와 연동하여 사용자 요청에 따라 결과 생성
- DB 서버의 역할
  - 데이터 저장 및 조회를 처리
  - WAS의 요청에 따라 데이터를 반환

### 리버스 프록시(Reverse Proxy)란?

🔍 클라이언트는 웹 서버만 알고, 실제 동작은 뒤에 있는 WAS가 처리하는 것

→ 웹 서버가 클라이언트를 대신해서 **WAS**에 요청을 전달하고,그 결과를 클라이언트에게 다시 전달하는 역할

- 장점
  - 백엔드 서버를 외부에 노출하지 않고 보호
  - 로드 밸런싱 기능 수행 가능
  - 캐싱을 통해 응답 속도 향상 가능
  - 보안 설정을 중앙에서 통제 가능

## 웹 서버와 WAS를 분리해서 사용하는 이유

- 역할 분리로 인한 성능 최적화
  - 웹 서버는 정적 콘텐츠 제공과 로드 밸런싱에 집중하고,
    WAS는 동적 콘텐츠 처리와 비즈니스 로직, DB 연동에 집중
    만약 모든 요청을 WAS가 처리한다면, 정적 콘텐츠까지 처리하게 되어 불필요한 부하가 발생하고, 전체 응답 속도가 느려질 수 있음
- 확장성과 장애 대응에 유리
  - 웹 서버는 여러 대의 WAS 인스턴스에 요청을 균등하게 분산할 수 있어 로드 밸런싱과 스케일 아웃이 가능
    따라서, 하나의 WAS에서 장애가 발생하더라도 웹 서버가 다른 정상 동작 중인 WAS로 요청을 자동 전환하기 때문에 서비스의 안전성과 연속성이 보장됨
- 보안 및 관리 측면의 이점
  - 웹 서버는 외부 요청을 직접 받는 프론트 엔드 역할을 하므로 인증, 접근 제어, HTTPS 처리 등을 웹 서버단에서 처리할 수 있음. 따라서 WAS는 직접 외부와 연결되지 않기 때문에 보안성이 높아짐
