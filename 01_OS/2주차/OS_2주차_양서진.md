# 메모리 관리 기법 (페이징, 세그멘테이션)

<img width="551" alt="image" src="https://github.com/user-attachments/assets/5cec45f0-4e58-432d-a78f-1a4d091c4bf0" />

- 프로그램을 실행하기 위해서는 메인 메모리에 코드와 데이터가 위치해야한다.
- 각각의 프로세스들은 own address space가 필요하다.
- 메모리를 효율적으로 관리할 방법이 필요하다
    - 메모리는 매우 비싼 시스템 자원이기 때문.

## 운영체제가 메모리 관련해서 하는 일

- 프로세스들에게 메모리 할당
- 프로세스들에게 독립된 주소공간 제공
- 프로세스를 메모리의 다른 위치로 옮길 수 있도록 허용 (dynamic linking)
- **물리적으로 연속된 메모리 공간을 제공**
- 메모리 단편화 문제를 해결하거나 최소화
- 캐싱

## Address in Computers (메모리 주소)

### 하나의 주소는 다양한 형태로 표현될 수 있다

- Physical address VS Logical address (가상화)
- Absolute address VS Relative address

### Physical address

메모리 유닛에 의해 보이는 주소

### Logical address (LA) or Virtual address(VA)

CPU에 의해 만들어지는 주소이다.

### Memort Management Unit (MMU) translate LA to PA

- 현대의 장치들은 CPU 코어의 일부분으로 MMU를 가지고 있음


<img width="968" alt="image2" src="https://github.com/user-attachments/assets/64a54235-2e34-4599-a4f0-d4d6ada8e713" />






**프로세서는 논리 주소(logical address)를 본다.**

**프로세스 또한 마찬가지이다.**

### MMU translates the LAs to PAs

- MMU는 LA에서 PA로 매핑 가능
- 각각의 프로세스들은 각각의 논리적 주소 공간을 가지고 있음

## 멀티 프로세스를 돌리게 되면

- 물리적인 공간은 한정적 → 겹칠 수 있음

<img width="660" alt="image3" src="https://github.com/user-attachments/assets/228f5b06-b5b1-4f40-be66-616b6e755454" />


---

## Segmentation

### An extension of variable partitions → 동적 파티션의 확장

Segmentation은 메모리를 고정 크기 파티션이 아닌, 각기 다른 크기의 '세그먼트'로 나눠 사용하는 방식

### **Divide address space into logical segments**

→ 주소 공간(address space)을 **논리적인 세그먼트(segment)**로 나눈다.

(*프로세스가 사용하는 메모리를 의미적으로 나누는 것*)

프로세스 하나당 **여러 개의 세그먼트**를 가질 수 있다.

### 각각의 세그먼트는 주소 공간에서 논리적인 entry에 대응된다.

- 예를 들어, 세그먼트는 **코드**, **데이터**, **스택**, **힙** 등을 포함할 수 있음

### 사용자(프로세스)는 메모리를 크기가 다양한 세그먼트들의 모음으로 본다.

보통 프로세스는 실행되기 위해 여러 가지 **기능별 메모리 영역**을 사용 
Ex)

- `코드 영역` (프로그램 명령어)
- `데이터 영역` (변수)
- `스택 영역` (함수 호출, 지역 변수)
- `힙 영역` (동적 할당)

---

### 📦 Segmentation(세그멘테이션)이란?

이런 각각의 영역을 **독립된 "세그먼트"**로 나누어서 관리하는 방식

그리고 이 세그먼트들은 **크기가 제각각**

그래서 프로세스가 메모리를 바라볼 때

> "한 덩어리의 연속된 공간"으로 보는 게 아니라
> 
> 
> **"여러 개의 기능별 구역(세그먼트)로 나뉜 조각들"로 본다**
> 

<img width="688" alt="image4" src="https://github.com/user-attachments/assets/92e7bfc2-041b-4916-bd1e-a6acb9256479" />


**가상 주소(Virtual Address)가 실제 물리 주소(Physical Address)로 어떻게 변환되는지**를 보여주는 그림

## 세그멘테이션 기반의 메모리 관리에서의 프로세스가 메모리를 어떻게 바라볼까?

프로세스가 보는건 Logical address 이다.

### 1. 💾 **Segment Table (세그먼트 테이블)**

| 항목 | 설명 |
| --- | --- |
| **Seg #** | 세그먼트 번호 (0: Code, 1: Data, 2: Heap, 3: Stack) |
| **Limit** | 세그먼트의 최대 길이 (예: 0x0600이면 1536 byte까지) |
| **Base** | 해당 세그먼트가 **물리 메모리에서 시작하는 주소** |
| **Dir** | 세그먼트가 증가(Up) 방향인지 감소(Down) 방향인지 |
| **Prot** | 접근 권한 (예: RW는 읽기/쓰기 가능) |

💡 이 테이블은 프로세스마다 가지고 있으며, **PCB(Process Control Block)**에 저장됨.

### 💾 **Segment Table (세그먼트 테이블)**

| 항목 | 설명 |
| --- | --- |
| **Seg #** | 세그먼트 번호 (0: Code, 1: Data, 2: Heap, 3: Stack) |
| **Limit** | 세그먼트의 최대 길이 (예: 0x0600이면 1536 byte까지) |
| **Base** | 해당 세그먼트가 **물리 메모리에서 시작하는 주소** |
| **Dir** | 세그먼트가 증가(Up) 방향인지 감소(Down) 방향인지 |
| **Prot** | 접근 권한 (예: RW는 읽기/쓰기 가능) |

💡 이 테이블은 프로세스마다 가지고 있으며, **PCB(Process Control Block)**에 저장됨.

<img width="149" alt="image5" src="https://github.com/user-attachments/assets/49e31064-e83f-446c-8fa7-8924f2c73f3e" />


> <1, 0x0362>
> 
- `1` → 세그먼트 번호 (**Data 세그먼트**)
- `0x0362` → 해당 세그먼트 안에서의 오프셋(offset)

→ Data 세그먼트의 0x0362에 접근하고 싶다는 뜻

### 🔁 **변환 과정**

1. 세그먼트 1(Data)의 **Limit: 0x0600**, **Base: 0xa000**
2. 오프셋 `0x0362`가 Limit보다 작으므로 → **접근 허용**
3. **Base (0xa000)** + **Offset (0x0362)** = **0xa362**
    
    → 위 주소가 접근하려는 물리적 주소이다.
    

즉 프로세스는 직접 물리 메모리를 보는 게 아니라, **논리적인 세그먼트들로 나눠진 메모리 공간** 을 보고 사용

그리고 OS와 MMU를 거쳐 실제 물리적인 주소로 변환된다.

## 각각의 프로세스들은 own segment table을 가지고 있다.

→  *프로세스마다 메모리 공간이 다르므로, 세그먼트 정보도 각각 따로 관리함*)

세그먼트 테이블의 최대 행 개수나, 열의 개수는 아키텍처에 따라 다양하다.

세그먼트 테이블은 CPU에 있는 **STBR(Segment Table Base Register)**를 통해 위치를 확인할 수 있다.

컨테스트 스위치가 발생시 세그먼트 테이블도 저장/복원 되어야 한다.

### 세그먼트 아이디는 explicit or implicit (명시적 또는 암시적이다.)

<img width="344" alt="image6" src="https://github.com/user-attachments/assets/ffe2ba15-08d2-409e-84d8-a8188209c9ca" />


암시적 형식은 주소값의 **상위 비트(MSB, Most Significant Bits)** 몇 개를 **세그먼트 ID로 해석**한다.

( *예를 들어, 전체 주소 중 앞의 몇 비트가 세그먼트 번호이고, 나머지가 offset으로 쓰임* )

### ✅ 1. **운영체제 (OS)** 의 역할

- **프로세스를 실행**할 때, 그 프로세스의 **세그먼트 테이블을 설정**함
- 세그먼트 테이블에는 각 세그먼트의:
    - **Base (물리 주소 시작점)**
    - **Limit (허용 가능한 최대 크기)**
    - **보호 정보 (읽기/쓰기 등)**
    - **방향 (up/down stack)**
        
        등이 포함됨
        
- 이 **세그먼트 테이블의 주소**를 **STBR(Segment Table Base Register)**에 기록함

🔹 즉, OS는 MMU가 참고할 수 있도록 세그먼트 정보를 "미리 준비"하는 역할!

---

### ✅ 2. **MMU (Memory Management Unit)** 의 역할

- *프로세스가 가상 주소 `<세그먼트 번호, 오프셋>`*를 사용해 메모리에 접근하려고 할 때,
MMU는 다음 작업을 자동으로 수행함:

### ✅ 변환 순서:

1. 세그먼트 번호에 해당하는 **Base, Limit 값**을 세그먼트 테이블에서 가져옴
    
    (이 테이블의 위치는 STBR가 알려줌 — 이것도 OS가 세팅해둠)
    
2. **오프셋(offset) < Limit** 인지 검사
    
    → ✅ 이 단계에서 Limit 체크는 **MMU 내부에서 수행됨**
    
    → 오프셋이 Limit보다 크면 → **Segmentation Fault (세그멘테이션 오류)**
    
3. Base + offset 계산 → 실제 **물리 주소**로 변환

## 세그멘테이션의 장단점

### 장점

- 메모리를 연속적으로 채우지 않고, 중간에 비워두고 필요한 곳에만 할당이 가능하다.
- 스택, 힙을 서로 독립적으로 늘리거나 줄일 수 있다.
    - 코드, 데이터, 스택,  힙 등이 서로 분리된 세그먼트이기 때문에 유연하게 조절 가능
- 각 세그먼트를 동적으로 재배치 할 수 있다.
    - Base만 변경하면 되기 때문에 프로세스의 세그먼트를 메모리 내에서 다른 우치로 옮겨도 괜찮다.
- 세그먼트 단위로 보호 설정이 용이하다.

### 단점

- 그래도 “하나의” 세그먼트는 연속된 공간에 할당 되어야 한다.
    - 하나의 블록으로 할당 되어야 한다.
- 지원할 수 있는 세그먼트가 많아질수록, 세그먼트 테이블의 크기가 커져서 오버헤드 증가
- External fragmentation이 발생할 수 있음

✅ 요약 정리

| 장점 | 단점 |
| --- | --- |
| 주소 공간을 드문드문 유연하게 할당 가능 | 세그먼트는 여전히 연속된 공간이 필요함 |
| Stack/Heap 독립적으로 크기 조절 가능 | 세그먼트가 많아지면 테이블 오버헤드 증가 |
| 각 세그먼트에 보호 권한 설정 가능 | 외부 단편화 발생 가능 |

---

## 중간 정리

1. 프로그램이 메모리에 올라가기 전 상태

| 구성 | 설명 |
| --- | --- |
| **코드(Code)** | 실행할 명령어들 (변하지 않음 → 읽기 전용) |
| **데이터(Data)** | 전역 변수 등 (읽고 쓰기 가능) |
| **힙(Heap)** | 동적 메모리 할당 영역 (malloc 등) |
| **스택(Stack)** | 함수 호출, 지역 변수 저장 (함수 호출 시마다 쌓임) |

→ 프로그램의 구성

메모리 관리 기법

## 🧾  세그멘테이션

> 위의 각 영역을 별도의 ‘세그먼트(Segment)’로 분리해서 메모리에 할당하는 방식
> 

### 🎯 핵심 개념:

- **메모리를 의미 단위로 나눔 (코드, 데이터, 힙, 스택 등)**
- 각 세그먼트는 **크기가 다를 수 있음 (variable size)**
- 각 세그먼트는 **연속된 공간**에 위치해야 함

---

## 🧾 3. 주소 접근 방식: 논리 주소 → 물리 주소

### 🧠 프로세스는 **논리 주소**를 사용:

<세그먼트 번호, 오프셋>
예: <1, 0x0023> → 세그먼트 1의 0x0023 위치

### 🔁 MMU가 물리 주소로 변환:

1. 세그먼트 테이블에서 해당 세그먼트의 `Base`와 `Limit` 가져옴
2. `오프셋 < Limit` 확인 (초과 시 segmentation fault)
3. `물리 주소 = Base + Offset` 계산

✅ 세그먼트 테이블은 **PCB에 저장**되며,

**OS가 프로세스를 전환할 때마다 로딩**됨

(MMU는 `STBR(Segment Table Base Register)`를 통해 테이블 참조)

---

## 🧾 4. 장점 ✅

| 항목 | 설명 |
| --- | --- |
| 의미 있는 메모리 단위 관리 | 코드, 데이터, 스택 등을 나눠 관리 |
| 유연성 | 스택/힙을 독립적으로 확장 가능 |
| 보호 설정 쉬움 | 코드 = 읽기 전용, 데이터 = 읽기/쓰기 등 개별 설정 가능 |
| 동적 재배치 가능 | Base 값만 바꾸면 세그먼트 이동 가능 |

---

## ⚠️ 5. 단점

| 항목 | 설명 |
| --- | --- |
| 외부 단편화 발생 | 세그먼트는 연속된 공간이 필요하므로 빈 공간이 생길 수 있음 |
| 테이블 오버헤드 | 세그먼트가 많아지면 세그먼트 테이블도 커짐 |
| 물리 메모리에 세그먼트를 연속적으로 배치해야 하므로 유연성 제한 |  |

## Paging

<img width="643" alt="image7" src="https://github.com/user-attachments/assets/3dbda8ca-f481-4792-8279-6788d9768e89" />


### 물리적인 메모리를 고정된 사이즈의 블럭으로 나누는 것. 
→**논리 주소 공간**과 **물리 주소 공간**을 **같은 크기 단위**로 나눔

이 블록들을 **페이지 프레임(page frames)** 또는 **프레임(frames)**이라고 부른다.

논리 주소 공간(프로세스가 사용하는 가상 메모리)도 **같은 크기의 블록**으로 나눈다.

→ 이 블록들을 **페이지(pages)**라고 부른다.

- 물리적인 메모리를 고정된 사이즈의 블럭으로 나눈 것 → 프레임
- 논리 주소 공간을 같은 크기의 블록으로 나눈 것 → 페이지

보통 프레임/페이지의 크기는 2의 제곱수이다.

K,M,G

- 크기가 n인 프로그램을 실행하려면, **n개의 빈 프레임**을 찾아 프로그램을 나눠서 로드한다.

(*이때, 연속된 공간이 아니어도 상관없음*)

운영체제(OS)는 **모든 빈 프레임의 상태를 관리**

프로세스의 **물리 메모리 공간은 연속적일 필요가 없다!**

### 그럼에도 불구하고 여전히 internal fragmentaion은 존재한다.



<img width="641" alt="image8" src="https://github.com/user-attachments/assets/aee07acd-ee66-4242-8f50-2a9474e45ebe" />

![image9](https://github.com/user-attachments/assets/585c7792-b115-4ec1-bfc6-d1cea42ef886)


## 🔸 전체 구조 설명

### 🧠 **1. 왼쪽: Virtual Address Space (가상 주소 공간)**

- `Process A`, `Process B` 각각 자신의 **가상 메모리(Virtual Pages)**를 가짐
- 여기서 나오는 Page 0, Page 1, ...은 전부 **논리적인 페이지 번호**
    
    → 이 주소는 실제 물리 메모리 주소가 아님
    

---

### 📋 **2. 가운데: Page Table (페이지 테이블)**

- **프로세스마다 하나씩 존재**함
    
    → `Page table for process A`, `Page table for process B`
    
- 페이지 테이블은 **가상 페이지 번호 ↔ 물리 프레임 번호**를 매핑(mapping)해주는 역할
- 예시:
    - `Process A`의 Page 0 → Frame 3
    - `Process A`의 Page 1 → Frame 1
    - `Process A`의 Page 3 → Frame 12
- 이 작업을 **주소 변환(address translation)**이라고 함
    
    → 실제 주소 계산은 **MMU(Memory Management Unit)가 수행함**
    

---

### 🧱 **3. 오른쪽: Physical Memory (물리 메모리)**

- 실제 RAM에 해당하는 공간
- 고정된 크기의 **Frame** 단위로 나눠져 있음 (프레임 = 페이지 크기와 동일)
- 각 Process의 페이지들이 **물리 메모리의 여러 위치(Frame)**에 **비연속적으로** 배치됨

📌 중요한 점:

- **물리 메모리는 연속되지 않아도 상관없음**
    
    → 외부 단편화 걱정이 없음!
    
- OS는 각 프로세스가 어떤 페이지를 어떤 프레임에 넣었는지 **Page Table**로 관리함

---

## 🔁 실제 주소 변환 과정 예시

### ▶️ 예: `Process A`가 자신의 Page 3을 접근한다고 가정하면:

1. 논리 주소 = `<Page 3, offset>`
2. MMU는 **Page Table for process A**를 조회
3. Page 3 → Frame 12로 매핑됨
4. 물리 주소 = `Frame 12의 시작 주소 + offset`
    
    ✅ 즉, 가상 주소 → 물리 주소로 변환 완료!
    

---

## 💡 요약 핵심 포인트

| 항목 | 설명 |
| --- | --- |
| **가상 주소** | 프로세스가 내부적으로 사용하는 주소 (`Page # + offset`) |
| **페이지 테이블** | 가상 페이지 번호를 물리 프레임 번호로 바꿔주는 매핑 정보 |
| **MMU** | 주소 변환 수행하는 하드웨어 (페이지 테이블 참조함) |
| **물리 주소** | 실제 RAM의 주소, Frame 단위로 접근 |
| **장점** | 연속된 메모리가 필요 없어 **외부 단편화 없음**, 메모리 활용도↑ |

## Page Tables

---

### 📌 각 프로세스는 자신만의 페이지 테이블을 가진다

- 각 프로세스마다 가상 메모리 구조가 다르기 때문에, 페이지 테이블도 따로 존재한다.

---

### 📌 페이지 테이블 기준 레지스터 (PTBR)

- 페이지 테이블이 메모리에서 어디에 있는지를 알려주는 레지스터
- 예: x86에서는 CR3 레지스터가 이 역할을 함

---

### 📌 가상 주소 구성

- 가상 주소는 `<가상 페이지 번호(VPN), 오프셋>` 형태
- VPN은 페이지 테이블에서 해당 항목을 찾는 인덱스
- 오프셋은 해당 페이지 내부의 실제 위치

---

### 📌 물리 주소 구성

- 물리 주소는 `<물리 프레임 번호(PFN), 오프셋>` 형태
- VPN을 통해 PFN으로 변환하고, 오프셋은 그대로 사용

---

### 📌 페이지 테이블 구조

- 페이지 테이블은 여러 개의 **페이지 테이블 엔트리(PTE)**로 이루어짐
- 각 PTE는 가상 페이지 하나에 대한 정보를 담고 있음 (어느 프레임에 있는지 등)

---

### 📌 운영체제와 MMU의 역할

- **운영체제(OS)**: 페이지 테이블을 생성하고 관리함
- **MMU**: 프로그램이 메모리에 접근할 때 페이지 테이블을 참조하여 가상 주소를 물리 주소로 변환함

## 페이징에서 가상주소가 물리주소로 변환되는 과정

| 용어 | 뜻 |
| --- | --- |
| **VPN (Virtual Page Number)** | 가상 페이지 번호 |
| **PPN (Physical Page Number)** | 물리 프레임 번호 |
| **오프셋 (Offset)** | 해당 페이지(프레임) 내부에서의 위치 |
| **가상 주소** | `<VPN, offset>`으로 구성됨 |
| **물리 주소** | `<PPN, offset>`으로 변환됨 |

![image10](https://github.com/user-attachments/assets/5aed48f7-f51d-4d10-8071-48ee0853835d)


## 🔍 그림 구성 설명

### ▶️ 왼쪽: 가상 주소 공간 (Virtual address)

- VPN 10과 VPN 11 두 개가 등장함
    
    예:
    
    - `0x1040`은 **VPN 10 + offset 0x40**
    - `0x1172`는 **VPN 11 + offset 0x72**

---

### ▶️ 가운데: 페이지 테이블 (Page Table)

- VPN 10 → **PPN 36**
- VPN 11 → **PPN 37**
- 이 매핑 정보는 **운영체제가 관리**하고, **MMU가 참조**함

---

### ▶️ 오른쪽: 물리 주소 공간 (Physical address)

- PPN 36 = 0x3600 ~ 0x36FF
- PPN 37 = 0x3700 ~ 0x37FF
- 여기에 offset을 더해서 최종 물리 주소 결정됨

---

### 🎯 예 1: `가상 주소 0x1040`

- VPN = 10, offset = 0x40
- 페이지 테이블에서 10 → 36 매핑
- 따라서 물리 주소는:
    
    → **PPN 36 + offset 0x40 = 0x3640**
    

---

### 🎯 예 2: `가상 주소 0x1172`

- VPN = 11, offset = 0x72
- 페이지 테이블에서 11 → 37 매핑
- 따라서 물리 주소는:
    
    → **PPN 37 + offset 0x72 = 0x3772**
    

💡 그림 맨 아래에 노란색으로 강조되어 있는 `0x3772`가 이 계산 결과

---

## ✅ 요약

- 가상 주소는 `<VPN, offset>`으로 구성됨
- MMU가 페이지 테이블을 통해 **VPN → PPN**으로 매핑
- 오프셋은 그대로 유지되어, 최종 물리 주소는 **PPN + offset**
- 이 방식은 물리 메모리를 **비연속적으로** 효율적으로 사용할 수 있게 해줌

---

# 가상 메모리 개념 (Demand Paging, Page Fault)

### 프로그램 로딩

모든 폰노이만 구조 장치 프로세서는 메인메모리에 올라와야만 데이터에 접근 할 수 있다.

그러나 하드디스크와 같은 저장 장치에 프로그램들을 설치해야하고, OS는 프로그램을 시작하기 위해서 메인 메모리에 모든것을 로드 해야함.

## Swapping

얼마나 많은 프로그램들을 동시에 실행할 수 있을까?

우리는 storage가 있기 때문에 메모리 크기의 총합보다 더 많은 크기의 프로세스들을 사용 가능하다.

## **Swap out a process temporarily to a backing store**

→ 프로세스를 **임시로 백업 저장소(보조 저장 장치)**로 스왑 아웃(swap out)한다.

(*즉, 메모리가 부족할 때 프로세스를 잠시 하드디스크 같은 공간으로 내보냄*)

## **Bring the process back into memory later for continued execution**

→ 그리고 나중에 그 프로세스를 **다시 메모리로 불러와서 실행을 계속한다.**

(*스왑 인(swap in)하여 이어서 실행함*)

<img width="637" alt="image11" src="https://github.com/user-attachments/assets/f6981b5f-181a-4e40-8097-008f1874548f" />


### 장점

실행 중인 모든 프로세스의 **메모리 총합이 실제 물리 메모리보다 클 수 있다.**

(*스와핑 덕분에, 물리 메모리에 다 올리지 않아도 운영 가능*)

### 단점

→스와핑은 **보통 시간이 오래 걸리며**, 그 속도는 **프로세스 크기와 백업 저장소(예: 하드디스크)의 데이터 전송 속도**에 따라 결정된다.

---

### **E.g., Swap out a process of 2GB, SATA3 supports up to 6 Gbps**

→ 예: 2GB짜리 프로세스를 스왑 아웃하는 경우, SATA3의 최대 속도는 6Gbps

### **→ 2 GB / (6Gb / 8) = 2.7 seconds**

→ 계산:

- 6Gbps ÷ 8 = 750MB/s
- 2GB ÷ 750MB/s ≈ **2.7초 소요**

→ 스왑 인(메모리로 다시 불러오기)까지 생각하면, **시간이 2배로 늘어날 수도 있다.**

(*총 5~6초 걸릴 수 있음*)

## 💡 **Solution (해결책)**

### **Allow processes to inform OS of memory use via system calls**

→ **프로세스가 시스템 콜을 통해 운영체제에 메모리 사용 계획을 알릴 수 있도록** 한다.

(*OS가 어떤 데이터를 우선순위로 관리할지 판단하는 데 도움*)

### **Allow to swap out only a part of processes in the memory**

→ **프로세스 전체가 아니라, 일부만 스왑 아웃할 수 있도록** 허용한다.

(*예: 사용 중이지 않은 코드나 데이터만 디스크로 내보냄 → 효율 ↑*)

---

> 스와핑을 이용하면 물리 메모리보다 더 많은 프로세스를 실행할 수 있다는 장점이 있지만,
> 
> 
> 스왑 입출력은 시간이 오래 걸린다는 단점이 있음.
> 
> 이를 개선하기 위해,
> 
> ① 프로세스가 메모리 사용 정보를 시스템 콜로 전달
> 
> ② 전체가 아닌 일부만 스왑 아웃하는 방식
> 

---

## Demand Paging

→ 페이지 단위로 스왑하는 페이징 시스템이다.

기존의 전체 프로세스 단위 스와핑과 달리, 필요한 **한 페이지씩만 불러오거나 내보냄**

즉, 한 프로세스에서 필요한 페이지만 로드 하는 것

**가상 메모리 구현의 핵심 기술이다.**

- 필요할 때만 메모리에 올려서
    
    **물리 메모리보다 더 큰 프로그램**도 실행 가능
    

`exec()` 시스템 콜을 호출한 프로세스에 대해, **처음에는 비어 있는(내용 없는) 페이지 테이블을 설정**한다. (*프로그램 실행 초기에는 실제 메모리에 아무 페이지도 올라와 있지 않음*)

프로그램이 **접근한 부분만** 실제 **주기억장치(main memory)**로 불러온다.

(*접근할 때마다 해당 페이지를 메모리로 로드함 → 지연 로딩*)

 이 때 **페이지 프레임이 할당**된다.

(*물리 메모리에서 해당 페이지를 담을 수 있는 공간을 배정함*)

만약 **물리 메모리가 가득 찬 상태**라면, 새로운 페이지를 넣기 위해 **다른 페이지를 쫓아내야(evict) 한다.**

쫓겨난 페이지는 **페이지 파일(paging file)** 또는 **디스크**로 이동한다.

(*즉, 스왑 파일로 저장해 둠*)

요약

프로그램 실행 초기엔 빈 페이지 테이블을 만들고,

접근이 일어날 때마다 페이지를 메모리에 올리며,

메모리가 부족하면 기존 페이지를 스왑 파일로 내보낸다.

이 과정은 **사용자에게는 보이지 않도록 자동 처리** 된다.

<img width="665" alt="image12" src="https://github.com/user-attachments/assets/85305f2a-d323-432b-9ee9-437cd8fdeae5" />


## 스왑 파일(Swap File)이란?

> 물리 메모리가 부족할 때, 메모리 데이터를 임시로 저장해 두는 하드디스크의 공간 
페이징 파일과 동일한 말
> 

### 페이지가 스왑아웃 될 때 (evicted)

<img width="529" alt="image13" src="https://github.com/user-attachments/assets/8973db4d-7555-4a04-b72c-b062982a060c" />


운영체제는 해당 페이지의 PTE (Page Table entry)를 다음과 같이 수정한다.

- Valid 비트(v)**를 `0`으로 설정 (→ **이 페이지는 메모리에 없음** 표시)
- PFN(Page Frame Number)은 **스왑 파일 내 위치 정보**로 갱신

### 페이지 접근 시 (evicted page is accessed)

- MMU는 PTE를 보고 **Valid 비트가 0**임을 확인 ⇒ 이 페이지가 메모리에 없다는 뜻
- 따라서 **MMU는 page fault 예외**를 발생시킴

메모리에 없는 페이지를 접근했기 때문에 운영체제에서 개입하여 처리해야 한다.

OS는 page fault handler를 실행함

- **PTE를 확인**해서 해당 페이지가 **스왑 파일로 옮겨졌는지** 확인
- 스왑 파일에서 다시 **해당 페이지를 메모리로 불러옴** (Swap-in)
- 만약 PFN이 `NULL`이면 → 올바르지 않은 접근
    
    ⇒ **SIGSEGV** (Segmentation Fault) 예외 발생
    
<img width="683" alt="image14" src="https://github.com/user-attachments/assets/52a9bd02-46c0-483b-940c-63b1ba8e060d" />



**스왑 아웃된 페이지에 접근할 때 발생하는 Page Fault 처리 과정**

**Page Fault 발생 → 복구 → 실행 재개**

![image15](https://github.com/user-attachments/assets/9adda69c-07f2-4bf1-9b11-6b7a0e851105)

<img width="611" alt="image16" src="https://github.com/user-attachments/assets/5fde71e8-1355-4563-aad3-dfb148c0e8c9" />



### 중간 정리

- Demand Page Step

1. MMU가 페이지 테이블에 대한 메모리를 address translation 시도
2. 실패시 페이지 fault가 발생한다.
3. OS의 Page fault handler가 불려옴
4. handler가 page table 확인, 확인후 decision
5. 만약 해당 내용을 disk에서 읽어들여야 한다면 메인메모리에서 빈 page(page frame)를 찾아 loading
6. 빈 프레임이 없다면 현재 메인 메모리에서 사용하지 않을 것 같은 Frame(victiom frame)을 페이징 파일로 이동한다. 
    1. 
    
    ### 어떤 페이지를 내보낼지 결정하는 건?
    
    - *Page Replacement Algorithm (페이지 교체 알고리즘)**이 판단함
    - 메모리는 결국 전체 데이터의 캐시 역할
7. 해당 victim page를 가지고 있던 프로세스의 페이지 테이블을 업데이트 한다.
8. 이번에 참조하려고 하는 페이지를 디스크에서 빈 페이지 테이블로 로딩한다.
9. 참조하려고 하는 페이지 테이블 수정후 실행을 다시 한다.

### Demand Paging은 "지역성의 원칙(Principle of Locality)"을 기반으로 동작함

---

### 📌 지역성(Locality)에는 두 가지 종류가 있음

| 종류 | 설명 | 해석 |
| --- | --- | --- |
| **Temporal locality** | 최근에 참조된 데이터는 **가까운 미래에 다시 참조될 가능성**이 높다 | → **한번 접근한 데이터는 또 접근될 것이다** |
| **Spatial locality** | 최근에 참조된 위치 주변의 데이터도 곧 참조될 가능성이 높다 | → **그 데이터 근처도 곧 접근될 것이다** |

- **프로그램의 메모리 접근 패턴**과 **데이터 크기**
- **페이지 교체 알고리즘 (Page replacement policy)**
- **물리 메모리의 크기**

그러나 이러한 요인들에 대해서 고려해야함 이에 따라 효율성이 달라질 수 있음 

# 캐시 메모리, TLB(Translation Lookaside Buffer)

## TLB

<img width="695" alt="image17" src="https://github.com/user-attachments/assets/a3029526-6cbb-4ba4-86da-6ac18b1fb9b4" />


페이지 테이블을 통한 주소 변환은 시간이 오래 소요된다.

- 이유: 페이지 테이블을 **여러 단계로 접근해야** 하므로 성능이 저하될 수 있음

Hierarchical Page Tables 와 같은 구조의 경우

 **3단계(3-level) 페이지 테이블**에서는 주소 변환을 하기 위해 **메모리에 3번 접근**해야 한다.

→ (각 단계마다 한 번씩 메모리에 접근해야 하므로 느림)

따라서 TLB는 **주소 변환을 가속화하기 위한 하드웨어 장치이다.**

TLB → Adderss Translation의 대한 캐시 역할이다.

- 페이지 테이블을 매번 접근하는 것을 피함
- **최근에 변환한 페이지 정보를 캐시**해둠

TLB는 보통 **32개 ~ 1024개 정도의 항목을 가진 캐시 메모리**

- 적지만 빠른 저장소 (캐시처럼 작고 빠르게 동작)

TLB는

```
<페이지 번호, 프레임 번호>
```

쌍을 저장함

→ 즉, **VPN → PFN** 매핑을 캐시해 둔 것

- TLB 미스(TLB miss) 발생하면,

→ **MMU**는 **페이지 테이블을 직접 탐색(walk)**해서 주소를 변환한 후, 그 변환 결과를 **TLB에 저장**한다.

(*즉, 캐시에 없는 경우, 원래처럼 느리게 찾아가고 → 결과를 다시 캐시에 넣음*)

- TLB 히트(TLB hit)가 발생하면,

→ **MMU는 페이지 테이블을 거치지 않고** 바로 가상 주소(VA)를 물리 주소(PA)로 변환할 수 있다.

(*즉, 캐시에 정보가 이미 있어서 빠르게 변환됨*)

- *컨텍스트 스위치(context switch)**가 발생하면,

→ **TLB는 비워져야(flush) 한다.**

(*왜냐하면 다음 프로세스는 전혀 다른 주소 공간을 사용하기 때문*)

- 각 프로세스는 **자신만의 VA → PA(가상 주소 → 물리 주소) 매핑**을 가진다.

(*즉, 프로세스마다 메모리 공간이 다름*)

- 따라서, **프로세스들 간에 TLB 항목을 공유할 수 없다.**

(*이전 프로세스의 주소 변환 정보는 다음 프로세스에 쓸 수 없음 → TLB 초기화 필요*)

하지만 **ASID(Address Space Identifier)** 기능이 있는 일부 TLB는

→ 여러 프로세스의 TLB 항목을 함께 저장(coexist) 할 수 있다.

# 메모리 할당 전략 (First Fit, Best Fit, Worst Fit)

## Fixed Partitions 고정 분할 방식

> 물리 메모리를 동일한 크기의 파티션(구역)으로 나눈다
> 

- 메모리 관리가 용이
- 어떤 파티션에 어떤 프로세스를 배치할지 결정

### Physical address = base address + logical address

- 프로세스가 사용하는 주소는 실제 메모리 주소가 아니라 논리적인 주소이며, 운영체제는 이를 기준 주소와 더해 실제 물리 주소로 변환

**Cannot access beyond its partition**

→ 자신의 파티션을 넘어서는 접근은 불가능하다.

(*즉, 각 프로세스는 할당된 메모리 범위를 넘어서 메모리에 접근할 수 없음. 보호 메커니즘*)

---

**The number of partitions = degree of multiprogramming**

→ 파티션의 수 = 다중 프로그래밍 정도

(*동시에 메모리에 올라올 수 있는 프로그램(프로세스)의 수는 파티션의 개수와 동일함*)

**Put a base register in MMU**

→ MMU(Memory Management Unit, 메모리 관리 장치)에 **기준 레지스터(base register)**를 넣는다.

(

*MMU는 논리 주소를 물리 주소로 변환하는 하드웨어 장치이며, base register는 프로세스가 접근할 수 있는 메모리의 시작점을 나타냄*

)

- OS가 프로세스를 전환할 때 해당 프로세스의 base register 값을 설정한다.
- 그리고 **논리 주소가 파티션 범위를 넘지 않았는지** 확인한다. → 논리 주소 ≥ 파티션 사이즈 라면 오류
    
    이렇게 하면 프로세스가 자신의 메모리 범위 내에서만 접근하게 하여 **메모리 보호**가 가능해진다.
    

<img width="695" alt="image18" src="https://github.com/user-attachments/assets/285a6335-993a-42c6-898b-8d394a3540b9" />


물리적 주소를 일정 크기로 자르고 각 구간에 프로세스 하나씩 대응

→ 각 프로세스 마다 대응되는 베이스 레지스터의 값이 다르다.

<img width="673" alt="image19" src="https://github.com/user-attachments/assets/8f1fc015-3524-4cac-a499-2c2120f12383" />


### 고정 분할 방식의 장단점

- 장점
    - 구현이 쉬움
    - Easy to validate access → 접근 권한 확인이 쉬움
        - 프로세스가 허용된 메모리 범위 내에서만 접근하는지 확인하는 작업이 간단
        - 논리 주소가 파티션 범위를 넘는지만 확인하면 된다
    - 컨텍스트 스위치가 빠르다
        - 컨텍스트 스위치를 진행할 때 base register만 저장하고 복구하면 된다.

- 단점
    - 동일한 크기의 파티션이면 조금만 사용하는 경우 메모리 낭비가 된다.
    - 하나의 고정된 크기로는 모든 프로세스에 적합하지 않다.
    - Internal fragmentation 내부 단편화
        - *프로세스가 파티션을 전부 사용하지 못하면 남은 공간이 낭비되는 문제. 예: 파티션은 100KB인데 프로세스는 70KB만 필요하면 30KB는 낭비됨*
    
    ## Fixed Partition의 가장 큰 단점
    
    ### Internal Fragmentation
    
    → 고정 분할 방식에 의해 메모리가 내부적으로 단편화된다.
    
    *메모리의 일부가 사용되지 못하고 빈 공간으로 남게 되는 것*
    
    자원이 고정된 크기의 chunk들로 나뉘어 각 인스턴스에 할당된다고 가정.
    
    각 메모리 청크는 인스턴스에 독점적으로 할당된다.
    
    해당 인스턴스가 자원에 일부분을 사용하지 않더라도 다른 인스턴스는 그 부분을 사용할 수 없다.
    
    **요구량은 다양**한데도 **자원이 고정 크기로 독점 할당**될 때, 이러한 문제가 발생한다.
    
<img width="197" alt="image20" src="https://github.com/user-attachments/assets/190e6d6e-2f5c-4780-a3d2-7df080d894b8" />

    
    ## Variable Partitions 동적 파티션
    
    ### External fragmentation
    
    - 메모리가 여기저기 쪼개져 있는 상태
    - 전체적으로 보았을 때 빈 공간이 충분하더라도 하나의 연속된 블록으로 존재하지 않으면 프로세스를 위한 메모리 할당이 불가하다
    
<img width="672" alt="image21" src="https://github.com/user-attachments/assets/bd5b985c-c16c-4672-af4f-1921ff9eba5b" />

    
    ## Allocation Strategies 할당 전략
    
    - First fit : 충분히 큰 첫 번째 빈 공간에 할당
        - *메모리를 앞에서부터 차례로 탐색하다가, 요청한 크기보다 크거나 같은 첫 번째 공간을 발견하면 거기에 바로 할당함*
    - Best fit : **요청한 크기보다 크거나 같은 빈 공간 중 가장 작은 공간**에 할당한다.
        - 요청한 크기를 수용할 수 있는 가장 작은 빈 공간에 할당
    - Worst fit: 가장 큰 공간을 할당하자
        - 즉, **작은 요청이 큰 공간을 차지하고**, 남는 조각이 또 다른 요청을 처리할 수 있게 하자는 전략
        - 반면, **작은 공간부터 채우면** 쓸 수 없는 조각이 남을 수도 있으니, 처음부터 큰 걸 나눠 쓰자는 생각
    
    Worst fit이 가장 최선의 방법이 될 것이다.
