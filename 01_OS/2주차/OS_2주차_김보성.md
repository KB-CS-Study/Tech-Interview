# ✅ 알고 가야할 점!

## 🧠 논리적 주소 vs 물리적 주소

| 항목 | 논리적 주소 | 물리적 주소 |
| --- | --- | --- |
| 의미 | CPU가 프로세스를 실행할 때 생성하는 주소 | 실제 RAM에서의 물리적인 위치 |
| 생성 위치 | CPU의 메모리 관리 장치가 생성 | 운영체제와 MMU가 변환해서 접근 |
| 사용 주체 |  CPU와 실행중인 프로그램 입장
(내가 쓰는 주소) | 운영체제/하드웨어 입장(진짜 위치) |
| 관계 | 논리 주소→ 물리주소로 변환되어야 실행 가능 | 변환된 결과 주소 |
| 예시 | 0x0000, 0x00A4
(내 프로그램 기준 주소) | 0xA124, 0xB568
(RAM 상 실제 위치) |

모든 프로세스는 자기 자신을 기준으로 논리적 주소는 번지 부터 시작하는 것처럼 보임!

- MMU : CPU 안에 있는 주소 변환 장치로, 논리적 주소(가상 주소)를 물리적 주소로 변환하는 역할
    - 메모리 보호 : 다른 프로세스 메모리 접근 막음
    - 페이지 테이블 관리 : 페이징 기법에서 주소 변환 시 테이블 참조
    - TLB 캐시 접근 : 빠른 주소 변환을 위해 캐시 먼저 확인
    - 가상 메모리, 페이징, 보호 기능 사용 가능하도록 도움

- 주소 바인딩 : CPU가 기계어 명령을 수행하기 위해 프로세스의 논리적 주소가 실제 물리적 메모리의 어느 위치에 매핑되는지 확인 하는 과정

![화면 캡처 2025-03-31 112345.png](attachment:8c41b770-0c4d-45d2-8af2-53c789b6aba1:화면_캡처_2025-03-31_112345.png)

![image.png](attachment:ec303d4b-8ede-4a73-bbdb-fcb1effaf807:image.png)

MMU는 CPU가 발생시킨 논리 주소에 베이스 레지스터 값을 더하여 논리 주소를 물리 주소로 변환하는 과정!

베이스 레지스터에 15000이 저장되어 있고 CPU가 발생시킨 논리 주소가 100번지라면 이 논리 주소는 물리 주소 15100번지로 변환됩니다. 

| 항목 | 값 |
| --- | --- |
| 베이스 레지스터 | 15000 |
| 한계 레지스터 | 5000 |
| 접근 가능한 논리 주소 | 0 ~ 4999 |
| 매핑되는 물리 주소 | 15000 ~ 19999 |
| 논리 주소 100 → 물리 주소 | ✅ 15100 |
| 논리 주소 6000 → 물리 주소 | ❌ 트랩 발생 (접근 불가!) → 인터럽트! |

논리 주소 + 베이스 레지스터 = 물리 주소

운영체제가 새로운 프로세스를 실행시키려고 메모리에 적재(load)할 때, 아래 2개를 설정함!

- 베이스 레지스터 : 프로세스가 사용할 수 있는 메모리의 시작 주소
- 한계 레지스터 : 그 프로세스가 사용할 수 있는 최대 크기(= 길이)를 제한

### 만약에 프로세스가 여러개라면?

| 프로세스 | 논리 주소 범위 | 베이스 레지스터 | 물리 주소 범위 |
| --- | --- | --- | --- |
| A | 0 ~ 999 | 10000 | 10000 ~ 10999 |
| B | 0 ~ 1999 | 20000 | 20000 ~ 21999 |
| C | 0 ~ 1499 | 30000 | 30000 ~ 31499 |

> 각자 논리 주소는 0부터 시작하지만
> 
> 
> 실제 메모리(RAM)에서는 전혀 **다른 영역**에 적재되도록 함!
> 

---

## ✅ 왜 둘이 나뉘어 있을까?

1. **보안성**: 프로세스가 서로의 메모리를 건드리지 못하게 분리할 수 있음
2. **효율성**: 물리 메모리 부족 시 가상 메모리 활용 가능
3. **가상 주소 공간** 제공: 물리 메모리보다 큰 주소 공간 제공 가능

---

## 🧩 주소 변환이 어떻게 이뤄질까?

1. CPU가 **논리적 주소**를 생성
2. MMU (Memory Management Unit)가 이를 받아
3. 페이지 테이블 / TLB를 통해 **물리적 주소로 변환**
4. 해당 **RAM 위치에 접근**

---

# ✅ 메모리 관리 기법

## 단편화

- 메모리를 할당할 때 전체 공간은 남아있지만 효율적으로 사용하지 못해서 사용할 수 없는 공간이
    
    생기는 것을 말함!
    
- 운영체자가 메모리를 남겨줄 때 생기는 남는 공간을 뜻하기도 함
- 메모리 낭비를 일으켜 성능 저하의 원인이 됨

### 📌 외부 단편화 (External Fragmentation)

![image.png](attachment:15494a76-8ffb-47ce-86d3-ce239b6c3539:image.png)

### ✅ 언제 생기나?

- **연속 메모리 할당**, **세그멘테이션**처럼 **다양한 크기의 메모리를 나눠줄 때** 발생
- 중간에 프로세스들이 종료되면 **애매하게 남는 빈 공간**들이 생기게 됨
    
    → **각 빈 공간에는 그 크기보다 작거나 같은 프로세스만 들어갈 수 있음**
    
    → 전체 용량은 충분해도, **연속된 공간이 없으면 큰 프로세스는 못 들어감!**
    

### 💡 예시

```
[ 사용 중 200KB ][ 빈 공간 120KB ][ 사용 중 300KB ][ 빈 공간 80KB ]

→ 총 빈 공간: 200KB  
→ 하지만 200KB짜리 연속된 공간은 없어!
```

### 🎯 해결 방법

- **압축(compaction)**: 메모리 조각들을 모아서 빈 공간을 한 곳에 몰아줌 (시간 소모 큼)
    - 단점 : 어느 빈 공간을 기준으로 모을지에 대한 알고리즘도 모호함
        
                    메모리에 적재된 프로세스를 정지시키고 한쪽으로 이동시키는 작업이 필요해 비효율
        

---

### 📌 내부 단편화 (Internal Fragmentation)

![image.png](attachment:b87904e1-3e11-40c5-a627-d416a8ba27f2:image.png)

### ✅ 언제 생기나?

- **고정된 크기의 블록**을 할당하는 방식(페이징 등)에서 발생
- 프로세스가 **블록 전체를 다 안 쓰면** 그 남는 부분이 낭비됨

### 💡 예시

- 페이지 크기: 4KB
- 프로세스가 6.2KB 필요
    
    → 2개 페이지 할당 (8KB)
    
    → 실제 사용은 6.2KB
    
    → **1.8KB 낭비** → 내부 단편화!
    

## 연속 메모리 할당

- 프로세스 하나가 연속된 물리 메모리 공간을 통째로 배정받는 방식
    - ex)  “어, 너 100KB 필요하니? 그럼 100KB 연속 공간 여기 있으니까 사용하세요~”

## ✅ 종류 (크게 2가지)

### 1. **단일 분할 방식**

- 모든 메모리를 **운영체제 + 사용자 프로그램 1개만** 사용하는 방식
- 예전 아주 초기 운영체제에서 쓰던 구조

```
css
복사편집
[ 운영체제 ][ 사용자 프로세스 ] → 끝
```

---

### 2. **다중 분할 방식**

- 메모리를 여러 조각으로 나누어 **여러 프로세스에 연속적으로 할당**
- 하지만 여전히 **각 프로세스는 한 덩어리로 메모리 받아야 함!**
- 중간에 프로세스가 종료되면 → **외부 단편화** 발생

```
css
복사편집
[ OS ][ P1 ][ 빈 공간 ][ P2 ][ 빈 공간 ][ P3 ] ...
```

---

## ✅ 장점

- 주소 변환이 간단 (Base + Offset 계산만 하면 됨)
- 하드웨어 구현 쉬움

---

## ⚠️ 단점

- **외부 단편화** 발생 → 빈 공간 생기지만 큰 프로세스 못 들어감
- 프로세스 크기에 맞는 연속된 공간이 필요하므로 유연성이 떨어짐
- 메모리 압축(compaction) 필요할 수 있음 (시간 소모 큼)

---

## 불연속 메모리 관리

위의 단편화 현상을 줄이고, 적절한 swapping을 통해 효율적으로 관리하려고 하기 위한 방법들!

프로세스를 쪼개서 물리 메모리 어디든 끼워 넣을 수 있음

![image.png](attachment:ec04251c-e974-473b-8827-f169587f9ff1:image.png)

### 1. **페이징 (Paging)**

### **개념**

- 하나의 프로세스가 사용하는 메모리 공간이, 연속적이어야 한다는 제약을 없애는 방법
- 메모리를 **고정 크기의 페이지**로 나누고, **프로세스**의 논리적 주소 공간도 같은 크기로 나누어 **매핑**하는 기법입니다.
- **물리적 메모리**도 **프레임**이라는 고정 크기로 나누어 **페이지**와 **프레임**을 대응시킵니다.

### **예시**

- 프로세스의 크기가 100KB라고 가정하고, 페이지 크기가 4KB라면 프로세스는 **25개의 페이지**로 나눠집니다.
- 물리적 메모리는 16KB짜리 프레임이 존재한다고 가정하면, 16KB마다 데이터를 할당하여 매핑합니다.

### **장점**:

- 외부 단편화 문제 해결

### **단점**:

- **페이지 테이블**을 관리해야 하므로 **오버헤드**가 발생
- 나눠서 저장하더라도 내부 단편화 문제가 여전히 발생할 수 있음
    - ex) 200으로 모두 나눠져 있을 때 950을 사용하면 마지막 블록에서 50이 비게 되는 경우

### 1-1 페이지 테이블

- 페이징을 쓰면 논리주소는 페이지 번호로 나뉘고 물리주소로 바꾸려면, 그 페이지가 메모리 어디에 있는지 알아야함!
- 그 위치 정보를 저장해둔 표가 바로 페이지 테이블!

### ✅ 페이지 테이블에 저장되는 정보

| 항목 | 설명 |
| --- | --- |
| 페이지 번호 | 논리 주소의 페이지 인덱스 |
| 프레임 번호 | 해당 페이지가 매핑된 실제 물리 메모리의 위치 |
| 접근 권한 | 읽기/쓰기 가능 여부 |
| valid/invalid 비트 | 페이지가 현재 메모리에 있는지 여부 (→ page fault 판별용) |

---

### 2. **세그멘테이션 (Segmentation)**

### **개념**

- 프로세스를 논리적인 단위(세그먼트)로 나누는 기법입니다.
    - 서로 다른 크기의 논리적 단위
    - 예를 들어, **코드**, **데이터**, **스택** 등을 별도로 분리하여 다룹니다.

### **예시**

- 예를 들어, 하나의 프로그램이 **코드**, **데이터**, **힙**, **스택**으로 나뉘어 있다고 가정하면:
    - **코드**: 실행할 명령어
    - **데이터**: 전역 변수와 정적 변수
    - **힙**: 동적 메모리 할당
    - **스택**: 함수 호출 시 지역 변수 및 반환 주소

### **장점**:

- 내부 단편화 해결
- 논리적으로 분리된 **각각의 세그먼트**를 관리하므로 코드와 데이터를 분리하여 **효율적인 처리**가 가능합니다.
- **유연성**이 높습니다.

### **단점**:

- **외부 단편화**가 발생할 수 있습니다
    - 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거 되는 일이 반복되면, 자유 공간들이 많은 수의 작은 조각들로 나누어져서 프로세스 할당이 어려운 현상 발생!

### 2-1 세그먼트 테이블

- 세그멘테이션은 프로그램을 코드, 데이터, 스택 등 **의미 있는 단위(세그먼트)**로 나누니까,
    
    각 세그먼트마다 **크기도 다르고, 위치도 다름!**
    
    → 그러니까 **"각 세그먼트가 어디에 위치해 있는지, 크기는 얼마인지"**
    
    → 이런 정보를 담아야 하는데 그걸 담은 게 바로 **세그먼트 테이블이야!**
    

### ✅ 세그먼트 테이블에 저장되는 정보

| 항목 | 설명 |
| --- | --- |
| 세그먼트 번호 | 코드, 데이터, 스택 등 |
| 베이스(Base) | 물리 메모리에서의 시작 위치 |
| 리밋(Limit) | 세그먼트의 크기 (최대 오프셋) |

---

# ✅가상 메모리 개념 (Demand Paging, Page Fault)

## 가상 메모리

### 개념

- 메모리가 실제 메모리 보다 많아 보이게 하는 기술!!
- 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 말에 착안하여 고안된 메모리 기법

### 사용하는 이유

| 이유 | 설명 |
| --- | --- |
| **물리 메모리는 작다** | 모든 프로세스를 한 번에 올리기엔 RAM이 부족함 |
| **효율적인 메모리 사용** | 실제 필요한 부분만 올려서 RAM을 절약할 수 있음 |
| **보안 & 독립성** | 프로세스마다 **자기만의 주소 공간**을 갖게 돼 (논리 주소 0부터 시작!) |

## 1. **Demand Paging (요구 페이징)**

### **개념**

- **필요할 때만** 페이지를 메모리로 불러오는 기법
- **프로세스**가 실행될 때, 처음에는 **필요한 페이지만 로드**하고, 다른 페이지는 **필요할 때만** 디스크에서 로드합니다.

### **예시**

- 프로그램이 실행될 때, 처음에 **첫 번째 페이지**만 메모리에 로드되고, 다른 페이지는 **사용자가 해당 페이지를 요구할 때** 로드됩니다.
- 예를 들어, 웹 브라우저에서 **탭을 클릭**할 때마다 해당 탭의 **메모리만 불러오는 방식**입니다.

### Demand Paging 방식!

1. 프로세스를 실행하면
    
    → 전체를 올리지 않고 일부 페이지만 메모리에 로드
    
2. 어떤 코드나 데이터를 사용하려고 하는데 그 페이지가 메모리에 없으면?
3. **Page Fault** 발생!
4. 운영체제가 **디스크에서 해당 페이지를 RAM에 올림**
5. 다시 실행 이어감

### **장점**:

- **메모리 절약**: 필요한 페이지만 로드되어 메모리를 효율적으로 사용할 수 있습니다.

### **단점**:

- 페이지 부재(Page Fault)가 자주 발생하면 **성능 저하**가 발생할 수 있습니다.

---

## 2. **Page Fault (페이지 부재)**

### **개념**

- 프로세스가 **필요한 페이지를 요청했지만**, 해당 페이지가 메모리에 없을 때 발생하는 현상
- 이는 메모리 접근 시도 중에 발생하는 인터럽트 도는 예외 상황
- 오류나 버그가 아니라 정상적으로 발생하는 운영체제 이벤트!!

### 목적

- 페이지 폴트 매커니즘은 프로세스가 필요로 하는 페이지를 효율적으로 로드하고 관리하는데 필요함
- 이를 통해 운영 체제는 물리적 메모리의 한정된 크기에도 불구하고, 프로세스가 더 큰 가상 메모리 공간을 사용할 수 있게 함!!

### **예시**

- 만약 웹 브라우저에서 특정 페이지를 클릭할 때, 해당 페이지가 메모리에 없다면 **Page Fault**가 발생하고, 운영체제는 디스크에서 페이지를 로드합니다.

### 페이지 폴트의 방식!

1. **페이지 폴트 발생**
    - 프로세스가 메모리에 접근하려 할 때, 해당 가상 주소에 대응하는 페이지가 물리적 메모리에 없으면 페이지 폴트가 발생합니다.
2. **인터럽트 처리**
    - 페이지 폴트는 운영 체제에 의해 처리되는 인터럽트입니다. 운영 체제는 이 인터럽트를 받고 현재 CPU의 상태를 저장한 후 페이지 폴트 처리 루틴을 실행합니다.
3. **페이지 로딩**
    - 운영 체제는 필요한 페이지를 찾아 물리적 메모리로 로드합니다. 이 페이지는 디스크의 스왑 영역이나 해당 파일 시스템에서 가져올 수 있습니다.
4. **페이지 테이블 업데이트**
    - 페이지가 메모리에 로드된 후, 페이지 테이블이 업데이트되어 새로운 매핑 정보를 반영합니다.
5. **프로세스 재개**
    - 페이지 로딩이 완료되면, CPU는 원래의 프로세스를 재개합니다.
    

### **장점**:

- 페이지가 **필요할 때만 메모리로 로드**되므로 메모리를 효율적으로 사용합니다.

### **단점**:

- **디스크 I/O**가 발생하므로, 페이지 부재가 많이 발생하면 성능이 저하될 수 있습니다.
- Page Fault가 너무 자주 발생하면 CPU는 일 못하고 디스크만 열심히 왔다갔다 함
    
    → Thrasing(스레싱) 이라고 함
    

### **Page Replacement Algorithm 간단 소개**

가상 메모리에서 **Page Fault가 발생했는데 메모리가 꽉 차 있으면?**

→ 하나를 내보내고 새 페이지를 넣어야 함

→ 이때 **어떤 페이지를 내보낼지 결정하는 알고리즘**이 필요해!

### 페이지 교체 알고리즘 소개

**FIFO (선입 선출)**

- 가장 먼저 들어온 페이지를 제거
- 요구하는 페이지가 없을 경우 점점 쌓이는 것!
- 아래 그림처럼 요구하는 페이지가 메모리 안에 있다면 교체없이 진행

![image.png](attachment:9027362a-ca1e-490d-9408-3ed7b1212b86:image.png)

**LRU (최근 최소 사용페이지 교체)**

- 최근 최소 사용 페이지 교체 알고리즘
- 지금 물리 메모리에 올라온 것들 중에서 가장 마지막에 사용되었던 것 빼기

![image.png](attachment:66e2dbd8-7051-4558-bd31-edfa50e16dbc:image.png)

**Optimal (최적의 사용페이지 교체)**

- 앞으로 가장 오랫동안 안 쓸 페이지 제거 (이론적으로만 가능)
- 4번 보면 원래 FIFO였다면 A를 빼고 D를 넣었을 텐데 앞으로 가장 오랫동안 안쓸 C를 제거하고 B를 메모리에 추가!

![image.png](attachment:5c1b86f6-0aae-486e-bf2c-3da454850568:image.png)

## 비교

### ✅ 1. **현실적 Best: LRU**

- **LRU는 현실에서 가장 성능 좋고 많이 쓰는 방식**
- 실제 메모리 사용 패턴을 반영해서
    
    → "덜 사용된 애를 내보내자"는 전략이니까 자연스러움
    

📌 근데 단점은?

→ 최근 사용 시간들을 추적해야 해서 하드웨어, 소프트웨어적으로 비용(오버헤드)이 큼

→ 그래서 완전한 LRU 대신에 **근사 방식** 많이 씀 (예: CLOCK 알고리즘)

---

### ✅ 2. **이론적 Best: Optimal**

- 페이지 폴트를 **가장 적게 만들 수 있는 이상적인 알고리즘**
- 문제는?  "앞으로 어떤 페이지를 언제 쓸지"를 알아야 함
    
    → 미래를 예측 할 수 없기에 현실에선 못 써 ❌
    
    → 단지 **다른 알고리즘 성능을 평가할 때 기준으로만 사용**
    

---

### ✅ 3. **기본형: FIFO**

- 구조 가장 단순! 그냥 **큐처럼** 가장 먼저 온 페이지 제거
- 하지만 실전에서는 **Belady's anomaly(이상 현상)** 발생
    
    → **페이지 수 늘렸는데 오히려 Page Fault 더 많아지는 경우도 있음!**
    

### 페이지 폴트의 유형 (**Minor Page Fault vs Major Page Fault)**

| 구분 | Minor Page Fault | Major Page Fault |
| --- | --- | --- |
| 정의 | 페이지는 이미 **메모리에 있음**, 매핑만 누락 | 페이지가 **메모리에 없음**, 디스크에서 불러와야 함 |
| 원인 | 페이지 테이블에 매핑 정보만 없어서 못 찾음 | 아예 메모리에 없고 디스크에서 읽어야 함 |
| 속도 | 빠름 (디스크 접근 ❌) | 느림 (디스크 접근 필요 ⏳) |
| 대표 상황 | 공유 메모리, fork 이후 | 일반적인 Demand Paging 상황 |

### Minor Page Fault

- 프로세스 A와 B가 같은 페이지 P를 공유함
- 프로세스 B는 아직 P에 매핑 안 됨
- B가 접근하면 → Minor Page Fault → 페이지 테이블만 갱신

### Major Page Fault

- 프로세스가 처음 쓰는 페이지
- 메모리에 없음 → 디스크에서 페이지 읽어와야 함
- Page Fault 처리 시간 ⏳ 더 걸림

---

# ✅ 캐시 메모리, TLB(Translation Lookaside Buffer)

### 1. **캐시 메모리 (Cache Memory)**

### **개념**

- **CPU와 메모리 사이에 존재하는 고속 메모리**로, 자주 사용되는 데이터를 저장하여 CPU가 빠르게 데이터를 처리할 수 있도록 합니다.

![image.png](attachment:3c44b959-6d82-43e7-82b1-c1dae8d0e5d5:image.png)

### **예시**

- 자주 사용하는 데이터를 캐시 메모리에 미리 저장하고, **CPU**는 이를 직접 읽어오는 방식입니다.
- 예를 들어, **웹 브라우저**에서 자주 방문하는 페이지를 **캐시**에 저장해두면, 다시 방문할 때 **빠르게 로딩**됩니다.

### **장점**:

- **CPU와 메모리의 속도 차이**를 줄여서 **성능을 향상**시킵니다.

---

### 2. **TLB (Translation Lookaside Buffer)**

### **개념**

- **페이지 테이블**을 캐싱하는 고속 버퍼로, 가상 주소를 물리 주소로 변환하는 **주소 변환**을 빠르게 수행합니다.
- 가상 주소 → 물리 주소 변환 시 자주 쓰는 변환 정보를 **임시 저장**하는 공간

### 필요한 이유

1. 주소 변환은 페이지 테이블을 참조
2. 근데 페이지 테이블은 메모리에 저장되어 시간이 더 걸림
3. 그래서 자주 쓰는 변환 정조만 TLB에 캐싱해두어 꺼내서 사용하면 빠르게 주소 변환 가능!
    - 이런식으로 사용하려는 주소 매핑이 있으면 **TLB Hit,** 없으면 **TLB Miss**로 다시 매핑해야함!

### **장점**:

- **주소 변환 속도**를 빠르게 하여 **시스템 성능**을 크게 향상시킵니다.

# ✅ 메모리 할당 전략 (First Fit, Best Fit, Worst Fit)

- **연속 메모리 할당!**
    - 프로세스를 메모리에 연속적으로 할당하는 기법
    - 할당과 제거를 반복하다보면 Scattered Holes가 생겨나고 이로 인한 외부 단편화가 발생

### 1. **First Fit**

### **개념**

- 메모리에서 첫 번째로 **충분히 큰 공간**을 찾아서 할당하는 방식입니다.

### **예시**

- 프로세스가 10MB 메모리를 요청했을 때, 첫 번째로 10MB 이상인 공간을 찾아 할당합니다.

### **장점**:

- 빠르게 **공간을 찾을 수 있는** 간단한 방식입니다.

### **단점**:

- **단편화**가 발생할 수 있습니다.

---

### 2. **Best Fit**

### **개념**

- 가장 **작은 빈 공간**을 찾아서 메모리를 할당하는 방식입니다.

### **예시**

- 10MB의 프로세스를 요청할 때, 10MB를 수용할 수 있는 **가장 작은 공간**을 찾아 할당합니다.

### **장점**:

- **단편화**가 줄어듭니다.

### **단점**:

- 매번 **최적 공간을 찾는** 계산이 필요하여 성능이 떨어질 수 있습니다.

---

### 3. **Worst Fit**

### **개념**

- 가장 **큰 빈 공간**을 찾아서 메모리를 할당하는 방식입니다.

### **예시**

- 10MB를 요청할 때, **가장 큰 빈 공간**을 찾아서 그 공간을 할당합니다.

### **장점**:

- **큰 공간을 잘 활용**하여 단편화를 줄일 수 있습니다.

### **단점**:

- 큰 공간이 **잘리게 되어** 더 작은 단편화가 생길 수 있습니다.